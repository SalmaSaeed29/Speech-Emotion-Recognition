{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#imports\nimport os\nimport h5py\nimport scipy\nimport math\nfrom sklearn import metrics\nimport numpy as np\nimport pandas as pd \nfrom IPython.display import Audio\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom matplotlib.pyplot import imread\nimport librosa\nimport librosa.display\n!pip install natsort\nimport natsort\nfrom scipy import signal\nfrom scipy.io import wavfile\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.layers as tfl\nfrom tensorflow.python.framework import ops\n\n\n%matplotlib inline\nnp.random.seed(1)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:10:12.576808Z","iopub.execute_input":"2023-05-17T19:10:12.577169Z","iopub.status.idle":"2023-05-17T19:10:23.519832Z","shell.execute_reply.started":"2023-05-17T19:10:12.577139Z","shell.execute_reply":"2023-05-17T19:10:23.518701Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: natsort in /opt/conda/lib/python3.10/site-packages (8.3.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"data_path = \"../input/speech-emotion-recognition-en/Crema\"","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:10:42.335093Z","iopub.execute_input":"2023-05-17T19:10:42.335478Z","iopub.status.idle":"2023-05-17T19:10:42.342446Z","shell.execute_reply.started":"2023-05-17T19:10:42.335445Z","shell.execute_reply":"2023-05-17T19:10:42.341522Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def load_data() :\n    labels = []\n    mel_spectograms=[]\n    features=[]\n\n    for file in natsort.natsorted(os.listdir(data_path)):\n        fileName = file.split(\"_\")\n        label=fileName[2]\n        path = os.path.join(data_path , file)\n        sound, sr = librosa.load(path, duration=3.5, sr=None)\n        sound_noise = noise(sound, random = True)\n        #sound_pitch = pitch(sound, sr, pitch_factor=0.5, random=True)\n        if librosa.get_duration(y = sound) < 3.5:\n          sound = np.pad(sound,(math.ceil((77175-sound.shape[0])/2),math.floor((77175-sound.shape[0])/2)), 'constant')\n          sound_noise = np.pad(sound_noise,(math.ceil((77175-sound_noise.shape[0])/2),math.floor((77175-sound_noise.shape[0])/2)), 'constant')\n          #sound_pitch = np.pad(sound_pitch,(math.ceil((77175-sound_pitch.shape[0])/2),math.floor((77175-sound_pitch.shape[0])/2)), 'constant')\n       \n        mel_spectograms.append(mel_spectogram(sound,sr))\n        mel_spectograms.append(mel_spectogram(sound_noise,sr))\n        #mel_spectograms.append(mel_spectogram(sound_pitch,sr))\n        \n        features.append(np.append(zero_crossingRate(sound), energy(sound)))\n        features.append(np.append(zero_crossingRate(sound_noise), energy(sound_noise)))\n        #features.append(np.append(zero_crossingRate(sound_pitch), energy(sound_pitch)))\n        \n        labels.extend([label]*2)\n        \n    return features, mel_spectograms, labels","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:11:40.368983Z","iopub.execute_input":"2023-05-17T19:11:40.369413Z","iopub.status.idle":"2023-05-17T19:11:40.382767Z","shell.execute_reply.started":"2023-05-17T19:11:40.369379Z","shell.execute_reply":"2023-05-17T19:11:40.380370Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def load_files(i,j):\n  files = sorted(os.listdir(data_path))\n  paths=[]\n  for i in range(i,j):\n    path = os.path.join(data_path , files[i])\n    paths.append(path)\n  return paths","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:11:47.475878Z","iopub.execute_input":"2023-05-17T19:11:47.476234Z","iopub.status.idle":"2023-05-17T19:11:47.484810Z","shell.execute_reply.started":"2023-05-17T19:11:47.476206Z","shell.execute_reply":"2023-05-17T19:11:47.483846Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def noise(data, random=False, rate=0.035, threshold=0.075):\n    \"\"\"Add some noise to sound sample. Use random if you want to add random noise with some threshold.\n    Or use rate Random=False and rate for always adding fixed noise.\"\"\"\n    if random:\n        rate = np.random.random() * threshold\n    noise_amp = rate*np.random.uniform()*np.amax(data)\n    data = data + noise_amp*np.random.normal(size=data.shape[0])\n    return data\n\ndef pitch(data, sampling_rate, pitch_factor=0.7, random=False):\n    \"\"\"\"Add some pitch to sound sample. Use random if you want to add random pitch with some threshold.\n    Or use pitch_factor Random=False and rate for always adding fixed pitch.\"\"\"\n    if random:\n        pitch_factor=np.random.random() * pitch_factor\n    return librosa.effects.pitch_shift(data, sr = sampling_rate, n_steps = pitch_factor)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:11:56.425473Z","iopub.execute_input":"2023-05-17T19:11:56.425814Z","iopub.status.idle":"2023-05-17T19:11:56.435526Z","shell.execute_reply.started":"2023-05-17T19:11:56.425787Z","shell.execute_reply":"2023-05-17T19:11:56.434377Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def mel_spectogram(sound,sr):\n    mel_spect = librosa.feature.melspectrogram(y=sound, sr=sr)\n    return np.expand_dims(mel_spect,2)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:12:06.307598Z","iopub.execute_input":"2023-05-17T19:12:06.308182Z","iopub.status.idle":"2023-05-17T19:12:06.316132Z","shell.execute_reply.started":"2023-05-17T19:12:06.308147Z","shell.execute_reply":"2023-05-17T19:12:06.315022Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def zero_crossingRate(sound):\n  return librosa.feature.zero_crossing_rate(y=sound)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:12:13.150013Z","iopub.execute_input":"2023-05-17T19:12:13.150411Z","iopub.status.idle":"2023-05-17T19:12:13.157869Z","shell.execute_reply.started":"2023-05-17T19:12:13.150379Z","shell.execute_reply":"2023-05-17T19:12:13.156298Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def energy(sound):\n   return librosa.feature.rms(y=sound)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:12:21.151975Z","iopub.execute_input":"2023-05-17T19:12:21.152356Z","iopub.status.idle":"2023-05-17T19:12:21.156997Z","shell.execute_reply.started":"2023-05-17T19:12:21.152299Z","shell.execute_reply":"2023-05-17T19:12:21.156055Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"features, mel_spectograms, labels = load_data()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:12:24.244596Z","iopub.execute_input":"2023-05-17T19:12:24.245390Z","iopub.status.idle":"2023-05-17T19:21:33.466887Z","shell.execute_reply.started":"2023-05-17T19:12:24.245351Z","shell.execute_reply":"2023-05-17T19:21:33.465350Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def get_splitted_data(data, labels):\n    # we startify the data corresponding to label as the should be dsitributed on all the splitted data\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size = 0.3, random_state=0,stratify = labels)\n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.05,random_state=0, stratify = y_train)\n\n    return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test), np.array(X_val), np.array(y_val)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:22:23.586563Z","iopub.execute_input":"2023-05-17T19:22:23.587287Z","iopub.status.idle":"2023-05-17T19:22:23.594657Z","shell.execute_reply.started":"2023-05-17T19:22:23.587248Z","shell.execute_reply":"2023-05-17T19:22:23.593605Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"x_train_2d, y_train_2d, X_test_2d, y_test_2d, X_val_2d, y_val_2d =  get_splitted_data(mel_spectograms, labels.copy())","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:22:25.925603Z","iopub.execute_input":"2023-05-17T19:22:25.926001Z","iopub.status.idle":"2023-05-17T19:22:26.678197Z","shell.execute_reply.started":"2023-05-17T19:22:25.925968Z","shell.execute_reply":"2023-05-17T19:22:26.677002Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# labels ['ANG' 'DIS' 'FEA' 'HAP' 'NEU' 'SAD']\nLABELS = {'ANG' : np.array([1, 0, 0, 0, 0, 0]),\n          'DIS' : np.array([0, 1, 0, 0, 0, 0]),\n          'FEA' : np.array([0, 0, 1, 0, 0, 0]),\n          'HAP' : np.array([0, 0, 0, 1, 0, 0]),\n          'NEU' : np.array([0, 0, 0, 0, 1, 0]),\n          'SAD' : np.array([0, 0, 0, 0, 0, 1])\n        }","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:22:29.082775Z","iopub.execute_input":"2023-05-17T19:22:29.083211Z","iopub.status.idle":"2023-05-17T19:22:29.093735Z","shell.execute_reply.started":"2023-05-17T19:22:29.083167Z","shell.execute_reply":"2023-05-17T19:22:29.092536Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"y_train_2d = np.array([LABELS[letter] for letter in y_train_2d])\ny_test_2d = np.array([LABELS[letter] for letter in y_test_2d])\ny_val_2d = np.array([LABELS[letter] for letter in y_val_2d])\nprint(y_train_2d.shape)\nprint(y_test_2d.shape)\nprint(y_val_2d.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:22:32.797836Z","iopub.execute_input":"2023-05-17T19:22:32.798225Z","iopub.status.idle":"2023-05-17T19:22:32.831176Z","shell.execute_reply.started":"2023-05-17T19:22:32.798195Z","shell.execute_reply":"2023-05-17T19:22:32.830066Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"(9897, 6)\n(4466, 6)\n(521, 6)\n","output_type":"stream"}]},{"cell_type":"code","source":"# 2D\nx_train_2d = (x_train_2d - np.min(x_train_2d)) / (np.max(x_train_2d) - np.min(x_train_2d))\nX_test_2d = (X_test_2d - np.min(X_test_2d)) / (np.max(X_test_2d) - np.min(X_test_2d))\nX_val_2d = (X_val_2d - np.min(X_val_2d)) / (np.max(X_val_2d) - np.min(X_val_2d))","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:22:37.767217Z","iopub.execute_input":"2023-05-17T19:22:37.768282Z","iopub.status.idle":"2023-05-17T19:22:39.350030Z","shell.execute_reply.started":"2023-05-17T19:22:37.768235Z","shell.execute_reply":"2023-05-17T19:22:39.348868Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def create_conv_model_2d(input_shape):\n  input_img = tf.keras.Input(shape=input_shape)\n  Z0 = tfl.Conv2D(256, 5, activation='relu', padding=\"same\", strides=1)(input_img)\n  Z1 = tfl.Conv2D(128, 5, activation='relu', padding=\"same\", strides=1)(Z0)\n  del(Z0)\n  P1 = tfl.MaxPool2D(pool_size=(5, 5), strides=(2, 2), padding='same')(Z1)\n  del(Z1)\n  Z2 = tfl.Conv2D(128, 5, activation='relu', padding=\"same\", strides=1)(P1)\n  del(P1)\n  P2 = tfl.MaxPool2D(pool_size=(5, 5), strides=(2, 2), padding='same')(Z2)\n  del(Z2)\n  Z3 = tfl.Conv2D(128, 5, activation='relu', padding=\"same\", strides=1)(P2)\n  del(P2)\n  P3 = tfl.MaxPool2D(pool_size=(5, 5), strides=(2, 2), padding='same')(Z3)\n  del(Z3)\n  F = tfl.Flatten()(P3)\n  del(P3)\n  FC1 = tfl.Dense(128, activation='relu')(F)\n  del(F)\n  FC2 = tfl.Dense(100, activation='relu')(FC1)\n  FC3 = tfl.Dense(10, activation='relu')(FC2)\n  del(FC2)\n  outputs = tfl.Dense(6, activation='softmax')(FC1)\n  del(FC1)\n    \n  # YOUR CODE ENDS HERE\n  model = tf.keras.Model(inputs=input_img, outputs=outputs)\n  return model","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:22:41.817275Z","iopub.execute_input":"2023-05-17T19:22:41.818021Z","iopub.status.idle":"2023-05-17T19:22:41.830751Z","shell.execute_reply.started":"2023-05-17T19:22:41.817984Z","shell.execute_reply":"2023-05-17T19:22:41.829561Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"conv_model_2d = create_conv_model_2d((128, 151, 1))\nopt3 = tf.keras.optimizers.Adam(learning_rate=0.0001)\nconv_model_2d.compile(optimizer=opt3,\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nconv_model_2d.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:22:46.459569Z","iopub.execute_input":"2023-05-17T19:22:46.459954Z","iopub.status.idle":"2023-05-17T19:22:50.923509Z","shell.execute_reply.started":"2023-05-17T19:22:46.459924Z","shell.execute_reply":"2023-05-17T19:22:50.922625Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 128, 151, 1)]     0         \n                                                                 \n conv2d (Conv2D)             (None, 128, 151, 256)     6656      \n                                                                 \n conv2d_1 (Conv2D)           (None, 128, 151, 128)     819328    \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 64, 76, 128)      0         \n )                                                               \n                                                                 \n conv2d_2 (Conv2D)           (None, 64, 76, 128)       409728    \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 32, 38, 128)      0         \n 2D)                                                             \n                                                                 \n conv2d_3 (Conv2D)           (None, 32, 38, 128)       409728    \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 16, 19, 128)      0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 38912)             0         \n                                                                 \n dense (Dense)               (None, 128)               4980864   \n                                                                 \n dense_3 (Dense)             (None, 6)                 774       \n                                                                 \n=================================================================\nTotal params: 6,627,078\nTrainable params: 6,627,078\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset_2d = tf.data.Dataset.from_tensor_slices((x_train_2d, y_train_2d)).batch(64)\ntest_dataset_2d = tf.data.Dataset.from_tensor_slices((X_val_2d, y_val_2d)).batch(64)\ncheckpoint_filepath_2d = '/content/gdrive/MyDrive/pr/Assignment_3/checkpoint_2dModel1FINAL'\nmodel_checkpoint_callback_2d = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath_2d,save_weights_only=True,monitor='val_accuracy',mode='max',save_best_only=True)\nhistory = conv_model_2d.fit(train_dataset_2d, epochs=90, validation_data=test_dataset_2d, callbacks=[model_checkpoint_callback_2d])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:22:56.796283Z","iopub.execute_input":"2023-05-17T19:22:56.797012Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/90\n155/155 [==============================] - 132s 626ms/step - loss: 1.6233 - accuracy: 0.3092 - val_loss: 1.5612 - val_accuracy: 0.3436\nEpoch 2/90\n 29/155 [====>.........................] - ETA: 1:09 - loss: 1.5404 - accuracy: 0.3534","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset_2d = tf.data.Dataset.from_tensor_slices((X_test_2d, y_test_2d)).batch(64)\nconv_model_2d.load_weights(checkpoint_filepath_2d)\nconv_model_2d.evaluate(test_dataset_2d)","metadata":{},"execution_count":null,"outputs":[]}]}